<!DOCTYPE html>
<html lang="zh-HK">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quackable!</title>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+HK:wght@400;500;700&family=Nunito:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #4F46E5;
            --primary-hover: #4338ca;
            --bg: #F3F4F6;
            --card-bg: #FFFFFF;
            --text-main: #1F2937;
            --text-sec: #6B7280;
            --accent: #10B981;
            --danger: #EF4444;
        }

        body {
            font-family: 'Nunito', 'Noto Sans HK', sans-serif;
            background-color: var(--bg);
            color: var(--text-main);
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }

        .container {
            background: var(--card-bg);
            width: 100%;
            max-width: 900px;
            border-radius: 20px;
            box-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.1), 0 8px 10px -6px rgba(0, 0, 0, 0.1);
            padding: 30px;
            box-sizing: border-box;
        }

        header {
            text-align: center;
            margin-bottom: 30px;
        }

        h1 {
            font-size: 2rem;
            margin: 0;
            color: var(--primary);
            font-weight: 800;
        }

        .subtitle {
            color: var(--text-sec);
            font-size: 1.1rem;
            margin-top: 5px;
        }

        .word-card {
            background: linear-gradient(135deg, #EEF2FF 0%, #E0E7FF 100%);
            border-radius: 16px;
            padding: 30px;
            text-align: center;
            margin-bottom: 30px;
            position: relative;
            border: 2px solid #C7D2FE;
        }

        .refresh-btn {
            position: absolute;
            top: 15px;
            right: 15px;
            background: rgba(255,255,255,0.8);
            border: none;
            border-radius: 50%;
            width: 36px;
            height: 36px;
            cursor: pointer;
            color: var(--primary);
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s;
            font-size: 18px;
        }
        
        .refresh-btn:hover {
            transform: rotate(180deg);
            background: white;
        }

        .target-word {
            font-size: 4rem;
            font-weight: 700;
            margin: 0;
            line-height: 1.2;
            color: var(--text-main);
        }

        .jyutping {
            font-size: 1.5rem;
            color: var(--primary);
            font-weight: 600;
            margin-top: 10px;
            font-family: 'Nunito', monospace;
        }

        .meaning {
            color: var(--text-sec);
            margin-top: 5px;
            font-size: 1rem;
        }

        .instructions {
            text-align: center;
            margin-bottom: 30px;
            color: var(--text-sec);
            background: #F9FAFB;
            padding: 15px;
            border-radius: 12px;
            display: inline-block;
            width: 100%;
            box-sizing: border-box;
        }

        .instruction-step {
            display: inline-block;
            margin: 0 10px;
            font-weight: 500;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
        }

        .btn-main {
            background: var(--primary);
            color: white;
            border: none;
            padding: 16px 32px;
            font-size: 1.1rem;
            font-weight: 600;
            border-radius: 50px;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 10px;
            transition: all 0.2s;
            box-shadow: 0 4px 6px -1px rgba(79, 70, 229, 0.3);
        }

        .btn-main:hover {
            background: var(--primary-hover);
            transform: translateY(-2px);
            box-shadow: 0 6px 8px -1px rgba(79, 70, 229, 0.4);
        }
        
        .btn-main:disabled {
            background: #D1D5DB;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .btn-main.recording {
            background: var(--danger);
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.4); }
            70% { box-shadow: 0 0 0 15px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }

        .viz-container {
            margin-top: 30px;
        }

        .canvas-wrapper {
            background: #FAFAFA;
            border-radius: 12px;
            padding: 15px;
            margin-bottom: 20px;
            border: 1px solid #E5E7EB;
        }

        .canvas-label {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text-sec);
            margin-bottom: 10px;
            display: flex;
            justify-content: space-between;
        }

        canvas {
            width: 100%;
            height: auto;
            border-radius: 8px;
            background: white;
            border: 1px solid #F3F4F6;
        }

        #transcript {
            font-size: 1.5rem;
            text-align: center;
            padding: 20px;
            border-radius: 12px;
            background: #F9FAFB;
            border: 2px dashed #E5E7EB;
            color: var(--text-sec);
            min-height: 1.5em;
        }
        
        .status {
            text-align: center;
            color: var(--text-sec);
            margin-bottom: 20px;
            font-size: 0.9rem;
            height: 1.2em;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Quackable</h1>
            <div class="subtitle">Practice your Cantonese Tones Á∑¥ÁøíÂª£Êù±Ë©±ËÅ≤Ë™ø</div>
        </header>

        <div class="word-card">
            <button class="refresh-btn" onclick="updateRandomWord()" title="New Word">‚Üª</button>
            <h2 class="target-word" id="targetWord">‰Ω†Â•Ω</h2>
            <div class="jyutping" id="targetJyutping">nei5 hou2</div>
            <div class="meaning" id="targetMeaning">Hello</div>
        </div>
        
        <div class="instructions">
            <span class="instruction-step">1. Press Record ÊåâÈåÑÈü≥</span> ‚Ä¢
            <span class="instruction-step">2. Read Aloud ÊúóËÆÄË©ûË™û</span> ‚Ä¢
            <span class="instruction-step">3. Check Tones Ê™¢Êü•ËÅ≤Ë™ø</span>
        </div>

        <div class="controls">
            <button id="recordBtn" class="btn-main" onclick="toggleRecording()">
                <span>üéôÔ∏è Start Record ÈñãÂßãÈåÑÈü≥</span>
            </button>
            <button id="playBtn" class="btn-main" onclick="playAudio()" disabled style="background-color: var(--accent);">
                <span>‚ñ∂Ô∏è Playback ÈáçÊí≠</span>
            </button>
        </div>

        <div class="status" id="status">Ready Ê∫ñÂÇôÂ∞±Á∑í</div>

        <div class="canvas-label">Recognized Text Ëæ®Ë≠òÊñáÂ≠ó</div>
        <div id="transcript">...</div>

        <div class="viz-container">
            <div class="canvas-wrapper">
                <div class="canvas-label">
                    <span>Spectrogram ËÅ≤Á¥ãÂúñ</span>
                    <span>0 - 4kHz</span>
                </div>
                <canvas id="spectrogramCanvas" width="800" height="300"></canvas>
            </div>

            <div class="canvas-wrapper">
                <div class="canvas-label">
                    <span>Pitch Contour ËÅ≤Ë™øÊõ≤Á∑ö (F0)</span>
                    <span>75 - 350Hz</span>
                </div>
                <canvas id="f0Canvas" width="800" height="200"></canvas>
            </div>
        </div>
    </div>

    <script>
        const words = [
            { word: "‰Ω†Â•Ω", jp: "nei5 hou2", en: "Hello" },
            { word: "Â§öË¨ù", jp: "do1 ze6", en: "Thank you (for gift/action)" },
            { word: "Êó©Êô®", jp: "zou2 san4", en: "Good morning" },
            { word: "ÂîîË©≤", jp: "m4 goi1", en: "Please / Thank you (service)" },
            { word: "È¶ôÊ∏Ø", jp: "hoeng1 gong2", en: "Hong Kong" },
            { word: "Âø´Ê®Ç", jp: "faai3 lok6", en: "Happy" },
            { word: "Â≠∏Áøí", jp: "hok6 zaap6", en: "Learn" },
            { word: "ÊúãÂèã", jp: "pang4 jau5", en: "Friend" },
            { word: "È£üÈ£Ø", jp: "sik6 faan6", en: "Eat meal" },
            { word: "ÂÜçË¶ã", jp: "zoi3 gin3", en: "Goodbye" },
            { word: "Â§©Ê∞£", jp: "tin1 hei3", en: "Weather" },
            { word: "ÂñúÊ≠°", jp: "hei2 fun1", en: "Like" }
        ];

        function updateRandomWord() {
            const random = words[Math.floor(Math.random() * words.length)];
            document.getElementById('targetWord').textContent = random.word;
            document.getElementById('targetJyutping').textContent = random.jp;
            document.getElementById('targetMeaning').textContent = random.en;
        }

        // Initialize random word on load
        window.onload = updateRandomWord;

        let audioContext;
        let mediaRecorder;
        let audioChunks = [];
        let audioBuffer;
        let isRecording = false;
        let recognition; // ASR instance
        const MAX_DURATION = 3000; // 3 seconds

        // Initialize Speech Recognition
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.lang = 'yue'; // Cantonese
            recognition.continuous = false;
            recognition.interimResults = false;
            
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                document.getElementById('transcript').textContent = transcript;
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error', event.error);
                if(event.error === 'no-speech') return; // Ignore no-speech, we might just be recording noise
                document.getElementById('transcript').textContent = '(ASR Error: ' + event.error + ')';
            };
        } else {
             document.getElementById('transcript').textContent = 'Web Speech API not supported in this browser.';
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    await processAudio(audioBlob);
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                if (recognition) {
                    try {
                        recognition.start();
                        document.getElementById('transcript').textContent = 'Listening...';
                    } catch (e) {
                         // Sometimes recognition is already started or other error
                        console.log("Recognition start error:", e);
                    }
                }

                isRecording = true;
                
                document.getElementById('recordBtn').textContent = 'Recording...';
                document.getElementById('recordBtn').classList.add('recording');
                document.getElementById('status').textContent = 'Recording... (3 seconds)';
                document.getElementById('playBtn').disabled = true;

                // Auto-stop after 3 seconds
                setTimeout(() => {
                    if (isRecording) {
                        stopRecording();
                    }
                }, MAX_DURATION);

            } catch (err) {
                console.error('Error accessing microphone:', err);
                document.getElementById('status').textContent = 'Error: Could not access microphone';
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                if (recognition) recognition.stop();
                isRecording = false;
                document.getElementById('recordBtn').textContent = 'Start Recording';
                document.getElementById('recordBtn').classList.remove('recording');
                document.getElementById('status').textContent = 'Processing...';
            }
        }

        async function processAudio(audioBlob) {
            const arrayBuffer = await audioBlob.arrayBuffer();
            let rawBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // Trim silence/noise
            audioBuffer = trimSilence(rawBuffer);

            if (audioBuffer.length === 0) {
                 document.getElementById('status').textContent = 'No voice detected.';
                 return;
            }

            drawSpectrogram(audioBuffer);
            drawF0Contour(audioBuffer);
            
            document.getElementById('status').textContent = 'Analysis complete! Click "Play Recording" to hear it.';
            document.getElementById('playBtn').disabled = false;
        }
        
        function trimSilence(buffer) {
            const data = buffer.getChannelData(0);
            const sampleRate = buffer.sampleRate;
            
            // Frame size for energy calculation (e.g. 10ms)
            const frameSize = Math.floor(sampleRate * 0.01);
            
            // Calculate energy profile
            const energies = [];
            let maxEnergy = 0;
            
            for (let i = 0; i < data.length; i += frameSize) {
                let sumSq = 0;
                const end = Math.min(i + frameSize, data.length);
                for (let j = i; j < end; j++) {
                    sumSq += data[j] * data[j];
                }
                const rms = Math.sqrt(sumSq / (end - i));
                energies.push(rms);
                if (rms > maxEnergy) maxEnergy = rms;
            }
            
            // Threshold relative to max energy (e.g., 5% or hard floor)
            // Using a hard floor is often safer for VAD if signal is weak, 
            // but relative is better for varied mic gains.
            // Let's use a combination: max(0.005, maxEnergy * 0.1)
            const threshold = Math.max(0.005, maxEnergy * 0.1); 
            
            let startFrame = 0;
            let endFrame = energies.length - 1;
            
            // Find start
            while (startFrame < energies.length && energies[startFrame] < threshold) {
                startFrame++;
            }
            
            // Find end
            while (endFrame > startFrame && energies[endFrame] < threshold) {
                endFrame--;
            }
            
            // If no voice found
            if (startFrame >= endFrame) {
                return buffer; // Return original if we can't determine, or return empty?
                               // Given requirement "remove parts with only noise", if only noise, maybe return empty.
                               // But user experience wise, returning original or empty might be confusing.
                               // Let's return empty to signal "no voice".
                 // Actually, let's keep it safe. If essentially silence, return it so spectrogram shows nothing.
            }
            
            // Add padding (e.g. 100ms)
            const paddingFrames = Math.floor(0.1 / 0.01); // 0.1s / frameSize_in_seconds
            startFrame = Math.max(0, startFrame - paddingFrames);
            endFrame = Math.min(energies.length - 1, endFrame + paddingFrames);
            
            const startTime = startFrame * 0.01;
            const endTime = (endFrame + 1) * 0.01;
            
            const startSample = Math.floor(startTime * sampleRate);
            const endSample = Math.floor(endTime * sampleRate);
            const length = endSample - startSample;
            
            const newBuffer = audioContext.createBuffer(
                buffer.numberOfChannels,
                length,
                sampleRate
            );
            
            newBuffer.copyToChannel(data.slice(startSample, endSample), 0);
            return newBuffer;
        }

        function drawSpectrogram(buffer) {
            const canvas = document.getElementById('spectrogramCanvas');
            const ctx = canvas.getContext('2d');
            const width = canvas.width;
            const height = canvas.height;

            ctx.clearRect(0, 0, width, height);

            const channelData = buffer.getChannelData(0);
            const sampleRate = buffer.sampleRate;
            
            // FFT parameters
            const fftSize = 1024; // Smaller FFT for better time resolution? Standard is 2048 or 1024.
            // Praat wideband usually effective 0.005s per frame. 
            // 2048 at 44.1k is ~46ms (narrowband).
            // 512 at 44.1k is ~11ms (wideband). 
            // Let's use 1024 for a balance or 512 for wideband (formant visible).
            // User asked for "Praat-like". Praat defaults to Wideband for spectrogram view.
            
            const effectiveFftSize = 1024; 
            const hopSize = 256;
            const numFrames = Math.floor((channelData.length - effectiveFftSize) / hopSize);
            
            // Create spectrogram data
            const spectrogram = [];
            let maxMagnitude = 0;

            for (let i = 0; i < numFrames; i++) {
                const start = i * hopSize;
                const frame = channelData.slice(start, start + effectiveFftSize);
                const spectrum = computeFFT(frame);
                spectrogram.push(spectrum);
                
                // Track max for normalization
                for (let j=0; j<spectrum.length; j++) {
                    if(spectrum[j] > maxMagnitude) maxMagnitude = spectrum[j];
                }
            }

            // Draw spectrogram (Praat: grayscale, dark=high energy)
            const displayMaxFreq = 5000;
            const freqBins = Math.floor((displayMaxFreq / (sampleRate/2)) * (effectiveFftSize / 2));
            const dynamicRange_dB = 50;
            
            for (let x = 0; x < Math.min(numFrames, width); x++) {
                const spectrum = spectrogram[x];
                for (let y = 0; y < Math.min(freqBins, height); y++) {
                    const magnitude = spectrum[y];
                    
                    // Log scale intensity
                    const dB = 20 * Math.log10((magnitude + 1e-9) / (maxMagnitude + 1e-9));
                    let intensityPercent = 0;
                    if (dB > -dynamicRange_dB) {
                        intensityPercent = (dB + dynamicRange_dB) / dynamicRange_dB;
                    }
                    
                    const gray = Math.floor(255 * (1 - intensityPercent));
                    ctx.fillStyle = `rgb(${gray},${gray},${gray})`;
                    
                    const yPos = height - (y * height / freqBins);
                    ctx.fillRect(x * width / numFrames, yPos, Math.ceil(width / numFrames) + 1, 2);
                }
            }

            // Add frequency labels
            ctx.fillStyle = 'black';
            ctx.font = '12px Arial';
            ctx.textBaseline = 'middle';
            ctx.textAlign = 'left';
            
            for (let f = 0; f <= displayMaxFreq; f += 1000) {
                const y = height - (f / displayMaxFreq) * height;
                ctx.fillText(`${f/1000}k`, 5, y);
                ctx.fillStyle = 'rgba(0,0,0,0.1)';
                ctx.fillRect(30, y, width, 1); // Guide line
                ctx.fillStyle = 'black';
            }
        }

        function drawF0Contour(buffer) {
            const canvas = document.getElementById('f0Canvas');
            const ctx = canvas.getContext('2d');
            const width = canvas.width;
            const height = canvas.height;

            ctx.clearRect(0, 0, width, height);

            const channelData = buffer.getChannelData(0);
            const sampleRate = buffer.sampleRate;
            
            // Extract F0 using autocorrelation
            const windowSize = 2048;
            // 1. One point per 10ms (0.01s)
            const hopSize = Math.floor(sampleRate * 0.010); 
            
            const numFrames = Math.floor((channelData.length - windowSize) / hopSize);
            const f0Values = [];

            for (let i = 0; i < numFrames; i++) {
                const start = i * hopSize;
                const frame = channelData.slice(start, start + windowSize);
                const f0 = detectPitch(frame, sampleRate);
                f0Values.push(f0);
            }

            // Fixed scale: 75-350 Hz
            const minF0 = 75;
            const maxF0 = 350;

            // Draw grid
            ctx.strokeStyle = '#e0e0e0';
            ctx.lineWidth = 1;
            ctx.font = '10px Arial';
            ctx.fillStyle = '#666';
            ctx.textAlign = 'left'; 
            ctx.textBaseline = 'middle';

            const step = 50; 
            for (let f = minF0; f <= maxF0; f += step) {
                const y = height - ((f - minF0) / (maxF0 - minF0)) * height;
                ctx.beginPath();
                ctx.moveTo(35, y);
                ctx.lineTo(width, y);
                ctx.stroke();
                ctx.fillText(`${f} Hz`, 2, y);
            }

            const jumpThreshold = 40; // Hz difference to consider "very different"
            
            // Draw points (pink/magenta like Praat)
            ctx.fillStyle = '#E91E63'; 
            
            // First pass: Draw dots
            for (let i = 0; i < f0Values.length; i++) {
                const f0 = f0Values[i];
                if (f0 >= minF0 && f0 <= maxF0) {
                    const x = (i / f0Values.length) * width;
                    const y = height - ((f0 - minF0) / (maxF0 - minF0)) * height;
                    ctx.beginPath();
                    ctx.arc(x, y, 2, 0, 2 * Math.PI);
                    ctx.fill();
                }
            }

            // Second pass: Draw connecting lines
            ctx.strokeStyle = '#2196F3';
            ctx.lineWidth = 2;
            ctx.beginPath();

            let started = false;
            let lastValidF0 = -1;
            
            for (let i = 0; i < f0Values.length; i++) {
                const f0 = f0Values[i];
                
                if (f0 >= minF0 && f0 <= maxF0) {
                    const x = (i / f0Values.length) * width;
                    const y = height - ((f0 - minF0) / (maxF0 - minF0)) * height;
                    
                    if (!started) {
                        ctx.moveTo(x, y);
                        started = true;
                    } else {
                        // Check if very different from surrounding (previous point)
                        const diff = Math.abs(f0 - lastValidF0);
                        if (diff > jumpThreshold) {
                            ctx.moveTo(x, y); // Don't connect
                        } else {
                            ctx.lineTo(x, y);
                        }
                    }
                    lastValidF0 = f0;
                } else {
                    started = false;
                    lastValidF0 = -1;
                }
            }
            ctx.stroke();

            // Labels
            ctx.fillStyle = 'black';
            ctx.font = '12px Arial';
            ctx.textAlign = 'right';
            ctx.fillText('Time ‚Üí', width - 10, height - 5);
        }

        function computeFFT(signal) {
            // Simple magnitude spectrum calculation
            const fftSize = signal.length;
            const spectrum = new Array(fftSize / 2).fill(0);
            
            // Apply Hamming window
            const windowed = signal.map((sample, i) => {
                const window = 0.54 - 0.46 * Math.cos(2 * Math.PI * i / (fftSize - 1));
                return sample * window;
            });

            // Compute power spectrum (simplified)
            for (let k = 0; k < fftSize / 2; k++) {
                let real = 0;
                let imag = 0;
                for (let n = 0; n < fftSize; n++) {
                    const angle = -2 * Math.PI * k * n / fftSize;
                    real += windowed[n] * Math.cos(angle);
                    imag += windowed[n] * Math.sin(angle);
                }
                spectrum[k] = Math.sqrt(real * real + imag * imag);
            }
            
            return spectrum;
        }

        function detectPitch(signal, sampleRate) {
            // Normalized Autocorrelation (NAC) for pitch detection
            const minFreq = 70;
            const maxFreq = 400;
            const minPeriod = Math.floor(sampleRate / maxFreq);
            const maxPeriod = Math.floor(sampleRate / minFreq);
            
            // RMS check for silence
            let sumSq = 0;
            for(let k=0; k<signal.length; k++) sumSq += signal[k]*signal[k];
            const rms = Math.sqrt(sumSq / signal.length);
            if (rms < 0.01) return 0;

            let maxCorrelation = -1;
            let bestPeriod = 0;
            
            // Standard Autocorrelation
            // R(k) = sum(x[i] * x[i+k])
            // Normalized R(k) = R(k) / sqrt(sum(x[i]^2) * sum(x[i+k]^2))
            
            // To be efficient, we compute terms carefully
            // Using a slightly smaller window to keep signal bounds
            const N = signal.length;
            
            for (let period = minPeriod; period < maxPeriod && period < N/2; period++) {
                let sumXY = 0;
                let sumXX = 0; 
                let sumYY = 0;
                
                // Compare signal[0...M] with signal[period...period+M]
                // where M = N - maxPeriod to be safe, or N-period
                // Let's use N - period as the window size for lag 'period'
                const limit = N - period;
                
                for (let i = 0; i < limit; i++) {
                    const x = signal[i];
                    const y = signal[i + period];
                    sumXY += x * y;
                    sumXX += x * x;
                    sumYY += y * y;
                }
                
                if (sumXX * sumYY > 0) {
                    const correlation = sumXY / Math.sqrt(sumXX * sumYY);
                    if (correlation > maxCorrelation) {
                        maxCorrelation = correlation;
                        bestPeriod = period;
                    }
                }
            }

            // Voicing threshold to avoid fricative noise detected as pitch
            // 0.45 is a reasonable empirical threshold for checking periodicity
            if (maxCorrelation < 0.45) {
                return 0; // Unvoiced
            }

            return bestPeriod > 0 ? sampleRate / bestPeriod : 0;
        }

        function getColorForIntensity(intensity) {
            // Helper for grayscale mapping (0-255)
            // Not used in main drawSpectrogram new logic, but kept for completeness
            // Maps 0 (low) -> 255 (high) to White -> Black
            const val = Math.max(0, Math.min(255, 255 - intensity));
            return `rgb(${val}, ${val}, ${val})`;
        }

        function playAudio() {
            if (audioBuffer) {
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start();
                document.getElementById('status').textContent = 'Playing...';
                source.onended = () => {
                    document.getElementById('status').textContent = 'Playback complete';
                };
            }
        }
    </script>
</body>
</html>